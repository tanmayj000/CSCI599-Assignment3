<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<title>assignment2</title>
		<style>
			body { margin: 0; }
		</style>
    <script type="importmap">
        {
          "imports": {
            "three": "https://unpkg.com/three@0.147.0/build/three.module.js",
            "three/addons/": "https://unpkg.com/three@0.147.0/examples/jsm/"
          }
        }
    </script>
	</head>
	<body>
		<script type="module" src="../js/assignment3.js"></script>

		<h1 style="text-align: center;">Assignment 3</h1>
		<h2>Introduction</h2>
		For this assignment, I trained both NERF and 3D Gaussian Splatting models on my own data. To achieve this, I used the nerfstudio
		library which come with implemented pipelines for both the models. 
		I captured my own data by placing a keg of beer on a stable surface and capturing about 50-100 images of the object from different
		angles using my smartphone camera. 

		Both the models require computation of camera information to work. Nerfstudio comes with helpful out-of-box functions to process
		images in supported format and compute camera transformations. It uses colmap as an engine to compute this information and hence colmap
		is one of the required packages. The two models were trained using google colab's T4 GPUs. 

		Lastly, we render high-definition videos of the 3-D models generated using the models. This was possible using the ns-render function in nerfstudio.
		The rendered videos have been added below as output results for the two models. Furthermore, I exported the point clouds generated by the two models
		as PLY files which have also been added below for visualization. 	


		<h2>3D Gaussian Splatting</h2>
		3D Gaussian splatting is a technique used in computer graphics and visualization to render point cloud data, such as those generated by 3D scanners or computed from other 3D models. Each point in the cloud is treated as a center of a Gaussian function, effectively representing it as a "splat" with a certain radius and fall-off. This method blends these splats together on a grid or in a volume to create a smooth, continuous surface or density field. The parameters of the Gaussian function, such as its standard deviation, control the smoothness and the extent of blending between the points. This technique is particularly useful in rendering noisy or sparse data, enhancing visual clarity and filling gaps between sampled points.
		<h3>Rendered Video:</h3>
		<video width="640" height="480" autoplay controls>
			<source src="../assets/3DGS/keg_splat_render.mp4" type="video/mp4">
		  Your browser does not support the video tag.
		</video>
		<h3>Point Cloud:</h3>
		<p>
		<div id="container2"></div>
		<h2>NERF</h2>
		Neural Radiance Fields (NeRF) is a novel technique in computer graphics and 3D modeling for synthesizing highly realistic images from sparse sets of 2D images. A NeRF model uses a deep neural network to map spatial coordinates and viewing directions to color and density, effectively learning a continuous volumetric scene function. The model is trained on a dataset of 2D images taken from multiple viewpoints, along with their camera parameters. During rendering, NeRF uses volume rendering techniques to integrate the contributions of light along rays cast through the scene, generating novel views that interpolate smoothly between the observed viewpoints. This approach allows for the production of complex scenes with fine geometric details and realistic view-dependent effects, such as reflections and occlusions, from a relatively small number of images.
		<h3>Rendered Video:</h3>

		<video width="640" height="480" autoplay controls>
			<source src="../assets/NERF/keg_nerf_render.mp4" type="video/mp4">
		  Your browser does not support the video tag.
		</video>
		</p>
		<h3>Point Cloud:</h3>

		<div id="container1"></div>

		</p>

	</body>
</html>

